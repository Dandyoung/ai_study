{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
      "[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# OpenAI API 키 설정 (이 예제에서는 사용되지 않음)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# SQLite 데이터베이스 경로\n",
    "db_path = \"/workspace/youngwoo/toyproject-datallm/modules/agent/tmp_dataset/Chinook.db\"\n",
    "\n",
    "# SQLite 데이터베이스 연결\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# 데이터베이스 방언 출력 (예: sqlite)\n",
    "print(db.dialect)\n",
    "\n",
    "# 사용 가능한 테이블 이름 출력\n",
    "print(db.get_usable_table_names())\n",
    "\n",
    "# SQL 쿼리 실행 및 결과 출력\n",
    "result = db.run(\"SELECT * FROM Artist LIMIT 10;\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 생성된 SQL Query :\n",
      "SELECT COUNT(EmployeeId) AS TotalEmployees\n",
      "FROM Employee\n",
      "\n",
      "\n",
      "2. SQL Query 실행 결과 :\n",
      "[(8,)]\n",
      "\n",
      "\n",
      "3. 최종 답변 :\n",
      "'현재 회사에는 8명의 직원이 있습니다.'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from operator import itemgetter\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "from langchain.globals import set_verbose\n",
    "from langchain.globals import set_debug\n",
    "set_verbose(False)\n",
    "set_debug(False)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\" \n",
    "사용자 질문에 친절하게 답변해 주세요.\n",
    "만약, 데이터베이스와 관련된 질문인 경우에는 사용자 질문, 해당하는 SQL 쿼리, 그리고 SQL 결과를 바탕으로 사용자 질문에 한국어로 답변해 주세요.\n",
    "\n",
    "- 데이터베이스 관련 질문일 경우 : \n",
    "질문: {question}\n",
    "SQL 쿼리: {query}\n",
    "SQL 결과: {result}\n",
    "답변: \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# StrOutputParser 설정\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer_prompt | llm | output_parser\n",
    ")\n",
    "\n",
    "\n",
    "response = chain.invoke({\"question\": \"몇명의 직원이 있어?\"})\n",
    "generated_sql = write_query.invoke({\"question\": \"몇명의 직원이 있어?\"})\n",
    "sql_result = db.run(generated_sql)\n",
    "\n",
    "print(\"1. 생성된 SQL Query :\")\n",
    "print(generated_sql)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"2. SQL Query 실행 결과 :\")\n",
    "print(sql_result)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"3. 최종 답변 :\")\n",
    "pprint.pprint(response)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'name': '이영우', 'email': 'duddn6464@naver.com', 'friends': ['최창우', '박지성']} 생성완료\n",
      "Validation error: 2 validation errors for User\n",
      "email\n",
      "  value is not a valid email address: The email address is not valid. It must have exactly one @-sign. [type=value_error, input_value='duddn6464', input_type=str]\n",
      "friends\n",
      "  Input should be a valid list [type=list_type, input_value='최창우, 박지성', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.7/v/list_type\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, EmailStr, ValidationError\n",
    "from typing import List\n",
    "\n",
    "# 사용자 모델 정의\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    friends: List[str]\n",
    "\n",
    "# 유효한 데이터 예시\n",
    "data_1 = {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"이영우\",\n",
    "    \"email\": \"duddn6464@naver.com\",\n",
    "    \"friends\": [\"최창우\", \"박지성\"]\n",
    "}\n",
    "\n",
    "# 유효하지 않은 데이터 예시\n",
    "data_2 = {\n",
    "    \"id\": \"1\",\n",
    "    \"name\": \"이영우\",\n",
    "    \"email\": \"duddn6464\",\n",
    "    \"friends\": \"최창우, 박지성\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    user = User(**data_1)\n",
    "    print(f\"{data_1} 생성완료\")\n",
    "except ValidationError as e:\n",
    "    print(\"Validation error:\", e)\n",
    "\n",
    "try:\n",
    "    user = User(**data_2)\n",
    "    print(f\"{data_2}생성완료\")\n",
    "except ValidationError as e:\n",
    "    print(\"Validation error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과가 나무에서 떨어지면... 사과했다!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "set_verbose(False)\n",
    "set_debug(False)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"나에게 {topic} 관련한 농담을 말해줘.\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "chain.invoke({\"topic\": \"사과\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사과가 나무에서 떨어지면서 외치는 소리는 뭐야? \"애플!\"',\n",
       " '커피는 삶의 유일한 즐거움이자, 새벽부터 밤늦게까지 나를 살려주는 최고의 친구야. 커피 없이는 나의 인생은 흑백사진처럼 지루하고 단조로울 거야. 커피는 나의 작은 행복이자, 큰 힘이야!']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"사과\"}, {\"topic\": \"커피\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "사\n",
      "과\n",
      "가\n",
      " 학\n",
      "교\n",
      "에\n",
      " 가\n",
      "면\n",
      " 무\n",
      "슨\n",
      " 과\n",
      "목\n",
      "을\n",
      " 듣\n",
      "게\n",
      " 될\n",
      "까\n",
      "요\n",
      "?\n",
      "\n",
      "\n",
      "\"\n",
      "과\n",
      "일\n",
      "과\n",
      "학\n",
      "\"\n",
      "입니다\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"사과\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith is a testing and observability platform built by the langchain team.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnablePassthrough\n",
    "from langchain_community.retrievers.tavily_search_api import TavilySearchAPIRetriever\n",
    "\n",
    "retriever= TavilySearchAPIRetriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based only on the context provided:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\"\"\")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "question = \"what is langsmith\"\n",
    "context = \"langsmith is a testing and observability platform built by the langchain team\"\n",
    "chain.invoke({\"question\": question, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=(lambda x: x[\"question\"]) | retriever\n",
    ") | chain\n",
    "\n",
    "retrieval_chain.invoke({\"question\": \"what is langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"{question}\"\"\")\n",
    "simple_chain = prompt | model | output_parser\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"retrieved_answer\": retrieval_chain,\n",
    "    \"simple_answer\": simple_chain\n",
    "})\n",
    "parallel_chain.invoke({\"question\": \"what is langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"{question}\"\"\")\n",
    "simple_chain = prompt | model | output_parser\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"retrieved_answer\": retrieval_chain,\n",
    "    \"simple_answer\": simple_chain\n",
    "})\n",
    "result = parallel_chain.invoke({\"question\": \"what is langsmith\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 + 9 = 12\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 사용자 정의 함수들\n",
    "def length_function(text):  # 텍스트의 길이를 반환 함수\n",
    "    return len(text)\n",
    "\n",
    "def _multiple_length_function(text1, text2):  # 두 텍스트의 길이를 곱하는 함수\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "def multiple_length_function(_dict):  # 딕셔너리에서 \"text1\"과 \"text2\"의 길이를 곱하는 함수\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "# prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}?\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 프롬프트와 모델을 연결하여 체인 생성\n",
    "chain1 = prompt | model\n",
    "\n",
    "# 체인 구성\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"input_1\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"input_1\"), \"text2\": itemgetter(\"input_2\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input_1\": \"bar\", \"input_2\": \"gah\"})\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
