{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/Mistral/Supervised_fine_tuning_(SFT)_of_an_LLM_using_Hugging_Face_tooling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oPAJl2uDmil"
      },
      "source": [
        "## Supervised fine-tuning (SFT) of an LLM\n",
        "\n",
        "ì§‘ì—ì„œ ChatGPTë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ì„¸ ê°€ì§€ ë‹¨ê³„ë¥¼ ê±°ì³ì•¼ í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. ì‚¬ì „ í›ˆë ¨(Pre-training): ì¸í„°ë„· ê·œëª¨ì˜ ë°ì´í„°ì—ì„œ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ë„ë¡ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‚¬ì „ í›ˆë ¨í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ìˆ˜ì²œ ê°œì˜ GPU í´ëŸ¬ìŠ¤í„°ì—ì„œ ìˆ˜í–‰ë˜ë©°, ê·¸ ê²°ê³¼ë¬¼ì„ \"ê¸°ë³¸ ëª¨ë¸\"ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
        "2. ì§€ë„í•™ìŠµ ë¯¸ì„¸ì¡°ì •(SFT): ê¸°ë³¸ ëª¨ë¸ì„ ìœ ìš©í•œ ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ì „í™˜í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.\n",
        "3. ì¸ê°„ ì„ í˜¸ë„ ê¸°ë°˜ ë¯¸ì„¸ì¡°ì •: ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì¹œê·¼í•¨, ìœ ìš©ì„± ë° ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ë‘ ë²ˆì§¸ ë‹¨ê³„ì¸ ì§€ë„í•™ìŠµ ë¯¸ì„¸ì¡°ì •(SFT), ë˜ëŠ” ì§€ì¹¨ ì¡°ì •ì— ëŒ€í•´ ì„¤ëª…í•  ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "ì§€ë„í•™ìŠµ ë¯¸ì„¸ì¡°ì •ì€ ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œ ì–»ì€ \"ê¸°ë³¸ ëª¨ë¸\"ì„ ë°”íƒ•ìœ¼ë¡œ, ì¸í„°ë„· í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ë„ë¡ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ \"ì±—ë´‡\" ë˜ëŠ” \"ì–´ì‹œìŠ¤í„´íŠ¸\"ë¡œ ì „í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ëŠ” êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ì„ ì‚¬ìš©í•˜ì—¬ ì¸ê°„ì˜ ì§€ì¹¨ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´, ëª¨ë¸ì€ ì—¬ì „íˆ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë˜ì§€ë§Œ, ì´ì œëŠ” \"ëŸ°ë˜ì—ì„œ í•  ìˆ˜ ìˆëŠ” 10ê°€ì§€ ì¼ì€ ë¬´ì—‡ì¸ê°€ìš”?\", \"íŒ¬ì¼€ì´í¬ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì€?\", \"ì½”ë¼ë¦¬ì— ëŒ€í•œ ì‹œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”\"ì™€ ê°™ì€ ì§€ì¹¨ì— ë”°ë¼ ìœ ìš©í•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„ë©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "ì´ë¥¼ ìœ„í•´ì„œëŠ” ì¸ê°„ ì£¼ì„ìê°€ ìœ ìš©í•œ ì™„ì„± ë¬¸ì¥ì„ ìˆ˜ì§‘í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, OpenAIëŠ”\n",
        "[ì‚¬ëŒë“¤ì„ ê³ ìš©í•˜ì—¬, í•´ë‹¹ ì‘ì—…ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.](https://gizmodo.com/chatgpt-openai-ai-contractors-15-dollars-per-hour-1850415474) ì´ë“¤ì€ \"ëŸ°ë˜ì—ì„œëŠ” ë¹…ë²¤ì„ ë°©ë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(...)\"ì™€ ê°™ì€ ì§€ì¹¨ì— ë”°ë¼ ìœ ìš©í•œ ì™„ì„± ë¬¸ì¥ì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­ë°›ì•˜ìŠµë‹ˆë‹¤. ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•œ SFT ë°ì´í„°ì…‹ì˜ í›Œë¥­í•œ ëª¨ìŒì€ [ì—¬ê¸°](https://huggingface.co/collections/HuggingFaceH4/awesome-sft-datasets-65788b571bf8e371c4e4241a)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "Notes:\n",
        "* ì „ì²´ ë…¸íŠ¸ë¶ì€ Hugging Faceì—ì„œ ê°œë°œí•œ [Alignment Handbook](https://github.com/huggingface/alignment-handbook)ì˜ ì£¼ì„ì´ ë‹¬ë¦° ë²„ì „ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìœ¼ë©°\n",
        "íŠ¹íˆ Zephyr-7b-betaë¥¼ í›ˆë ¨í•˜ëŠ” ë° ì‚¬ìš©ëœ [recipe](https://github.com/huggingface/alignment-handbook/blob/main/recipes/zephyr-7b-beta/sft/config_lora.yaml)ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. \n",
        "\n",
        "* ì´ ë…¸íŠ¸ë¶ì€ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ë””ì½”ë” ì „ìš© LLMì— ì ìš©ë©ë‹ˆë‹¤. ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” í˜„ì¬ ì‘ì„± ì‹œì ì—ì„œ ê°€ì¥ ìš°ìˆ˜í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ì¤‘ í•˜ë‚˜ì¸ [Mistral-7B base model](https://huggingface.co/mistralai/Mistral-7B-v0.1)ì„ ë¯¸ì„¸ì¡°ì •í•  ê²ƒì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjdw05Rk5fYm"
      },
      "source": [
        "## Required hardware\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ [Ampere architecture](https://en.wikipedia.org/wiki/Ampere_(microarchitecture))ì´ìƒì„ ì§€ì›í•˜ë©°, ìµœì†Œ 24GBì˜ RAMì„ íƒ‘ì¬í•œ NVIDIA GPUì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. \n",
        "\n",
        "í¬í•¨ë˜ëŠ” GPUëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "\n",
        "* NVIDIA RTX 3090, 4090\n",
        "* NVIDIA A100, H100, H200\n",
        "\n",
        "ë“±ë“±. ê°œì¸ì ìœ¼ë¡œ ì €ëŠ” 24GB RAMì„ íƒ‘ì¬í•œ RTX 4090ì—ì„œ ì´ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•”í˜ì–´ ì•„í‚¤í…ì²˜ë¥¼ ìš”êµ¬í•˜ëŠ” ì´ìœ ëŠ” [bfloat16 (bf16) format](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format)ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì¸ë°, ì´ëŠ” Turingê³¼ ê°™ì€ ì´ì „ ì•„í‚¤í…ì²˜ì—ì„œëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "\n",
        "í•˜ì§€ë§Œ ì•½ê°„ì˜ ìˆ˜ì •ìœ¼ë¡œ float16 (fp16) í¬ë§·ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì´ì „ ì„¸ëŒ€ GPUì—ì„œë„ ì§€ì›ë©ë‹ˆë‹¤. \n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´:\n",
        "\n",
        "* NVIDIA RTX 2080\n",
        "* NVIDIA Tesla T4\n",
        "* NVIDIA V100.\n",
        "\n",
        "bf16ì„ fp16ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•˜ëŠ” ìœ„ì¹˜ì— ëŒ€í•œ ì£¼ì„ì´ ì¶”ê°€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "## Set-up environment\n",
        "\n",
        "ì§€ë„ í•™ìŠµ ë¯¸ì„¸ì¡°ì •ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ëª¨ë“  ğŸ¤— ë„êµ¬ë“¤ì„ ì„¤ì¹˜í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‹¤ìŒì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤:\n",
        "\n",
        "* Transformers: ë¯¸ì„¸ì¡°ì •í•  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ìœ„í•´\n",
        "* Datasets: ğŸ¤— í—ˆë¸Œì—ì„œ SFT ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ëª¨ë¸ì— ë§ê²Œ ì¤€ë¹„í•˜ê¸° ìœ„í•´\n",
        "* BitsandBytes ë° PEFT: ì†Œë¹„ì í•˜ë“œì›¨ì–´ì—ì„œ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •í•˜ê¸° ìœ„í•´ [Q-LoRa](https://huggingface.co/blog/4bit-transformers-bitsandbytes)ë¥¼ í™œìš©í•˜ëŠ”ë°, ì´ëŠ” ë¯¸ì„¸ì¡°ì •ì— í•„ìš”í•œ ê³„ì‚° ìì›ì„ í¬ê²Œ ì¤„ì—¬ì£¼ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
        "* TRL: LLM ë¯¸ì„¸ì¡°ì •ì„ ìœ„í•œ ìœ ìš©í•œ Trainer í´ë˜ìŠ¤ë¥¼ í¬í•¨í•˜ëŠ” [library](https://huggingface.co/docs/trl/index)ì…ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "ì´ì œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•´ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-9357hGFRqdi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers[torch] datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rxpq51gW_ySc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q bitsandbytes trl peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RgDwMbXpC4L"
      },
      "source": [
        "ìš°ë¦¬ëŠ” ë˜í•œ ëª¨ë¸ì˜ ì–´í…ì…˜ ê³„ì‚°ì„ ê°€ì†í™”í•˜ëŠ” [Flash Attention](https://github.com/Dao-AILab/flash-attention)ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "* --no-build-isolation ì„ ì“´ ì´ìœ ëŠ” ì‚¬ëŒë§ˆë‹¤ CUDA , Pytorch ë²„ì „ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—,, í•¨ë¶€ë¡œì“°ë©´ dependency ë¬¸ì œê°€ ìƒê¸¸ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNJvtR1wGxHm",
        "outputId": "545b75a3-932e-4195-f74a-a6f3447f67de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-^C\n",
            "\u001b[?25canceled\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'no' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install flash-attn --no-build-isolation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[43mno\u001b[49m\u001b[38;5;241m-\u001b[39mbuild\u001b[38;5;241m-\u001b[39misolation\n",
            "\u001b[0;31mNameError\u001b[0m: name 'no' is not defined"
          ]
        }
      ],
      "source": [
        "!pip install flash-attn --no-build-isolation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJIqlyI15kj8"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "Note :ê°€ì´ë“œëŠ” ì—¬ëŸ¬ ë°ì´í„°ì…‹ì„ í˜¼í•©í•˜ì—¬ ê° ë°ì´í„°ì…‹ì´ ì¼ì • ë¹„ìœ¨ì˜ í•™ìŠµ ì˜ˆì œë¥¼ í¬í•¨í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ Zephyr ë ˆì‹œí”¼ëŠ” ë‹¨ì¼ ë°ì´í„°ì…‹ë§Œ ì‚¬ìš©í•˜ë©°, í•´ë‹¹ ë°ì´í„°ì…‹ì€ [UltraChat200k dataset](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k)ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YhYvRDF25j59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# based on config\n",
        "raw_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFYvJUfODabt"
      },
      "source": [
        "ë°ì´í„°ì…‹ì€ ì—¬ëŸ¬ ë¶„í• ë¡œ ë‚˜ë‰˜ì–´ ìˆìœ¼ë©°, ê° ë¶„í• ë§ˆë‹¤ íŠ¹ì • ìˆ˜ì˜ í–‰ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì €í¬ëŠ” ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(SFT)ì„ ì§„í–‰í•  ì˜ˆì •ì´ê¸° ë•Œë¬¸ì— \"train_sft\"ì™€ \"test_sft\" ë¶„í• ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX1sIK6X6Opi",
        "outputId": "f0ab2b40-6789-44c4-ece2-bd84e0d5fa65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# remove this when done debugging\n",
        "indices = range(0,100)\n",
        "\n",
        "dataset_dict = {\"train\": raw_datasets[\"train_sft\"].select(indices),\n",
        "                \"test\": raw_datasets[\"test_sft\"].select(indices)}\n",
        "\n",
        "raw_datasets = DatasetDict(dataset_dict)\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sByKH4hd8mUm"
      },
      "source": [
        "ì¢‹ìŠµë‹ˆë‹¤. í•˜ë‚˜ì˜ ì˜ˆì œë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. ê° ì˜ˆì œê°€ ë©”ì‹œì§€ ëª©ë¡ì„ í¬í•¨í•´ì•¼ í•œë‹¤ëŠ” ì ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2XwVpT17TAb",
        "outputId": "8d441fee-4a0b-4310-9a30-86b4439e0609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['prompt', 'prompt_id', 'messages'])\n"
          ]
        }
      ],
      "source": [
        "example = raw_datasets[\"train\"][0]\n",
        "print(example.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaWnT4uBCjTy"
      },
      "source": [
        "ê° ë©”ì‹œì§€ëŠ” ë‘ ê°œì˜ í‚¤ë¥¼ í¬í•¨í•˜ëŠ” ì‚¬ì „(dictionary)ì…ë‹ˆë‹¤:\n",
        "\n",
        "* \"role\": ë©”ì‹œì§€ì˜ ì‘ì„±ìë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ê°’ì€ \"system\", \"assistant\", ë˜ëŠ” \"user\"ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ \"user\"ëŠ” ì‚¬ëŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "* \"content\": ë©”ì‹œì§€ì˜ ì‹¤ì œ ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "ë‹¤ìŒì€ ì´ í•™ìŠµ ì˜ˆì œì˜ ë©”ì‹œì§€ ì‹œí€€ìŠ¤ë¥¼ ì¶œë ¥í•œ ì˜ˆì…ë‹ˆë‹¤:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ1sMda27Zj6",
        "outputId": "04b5ab19-2910-4f1b-91cb-3aece687e49b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user                :  These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
            "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
            "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
            "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?\n",
            "assistant           :  This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\n",
            "user                :  Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?\n",
            "assistant           :  Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
            "\n",
            "1. Log in to your Shopify account and go to your Online Store.\n",
            "2. Click on Customize theme for the section-based theme you are using.\n",
            "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
            "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
            "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
            "6. If available, select 'Show secondary image on hover'.\n",
            "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
            "\n",
            "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\n",
            "user                :  Can you provide me with a link to the documentation for my theme?\n",
            "assistant           :  I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\n",
            "user                :  Can you confirm if this feature also works for the Quick Shop section of my theme?\n",
            "assistant           :  The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
            "\n",
            "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\n"
          ]
        }
      ],
      "source": [
        "messages = example[\"messages\"]\n",
        "for message in messages:\n",
        "  role = message[\"role\"]\n",
        "  content = message[\"content\"]\n",
        "  print('{0:20}:  {1}'.format(role, content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DL8S3dkT2Av"
      },
      "source": [
        "ì´ë²ˆ ê²½ìš°, ì§€ì¹¨ì´ Shopifyì—ì„œ íŠ¹ì • ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ëŠ” ê²ƒì— ê´€í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. í¥ë¯¸ë¡­êµ°ìš”!\n",
        "\n",
        "\n",
        "(ShopifyëŠ” ì¢…í•© ìƒê±°ë˜ í”Œë«í¼ì´ë‹¤.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVRxCJQ76spF"
      },
      "source": [
        "## Load tokenizer\n",
        "\n",
        "Next, we instantiate the tokenizer, which is required to prepare the text for the model. The model doesn't directly take strings as input, but rather `input_ids`, which represent integer indices in the vocabulary of a Transformer model. Refer to my [YouTube video](https://www.youtube.com/watch?v=IGu7ivuy1Ag&ab_channel=NielsRogge) if you want to know more about it.\n",
        "\n",
        "\n",
        "ë‹¤ìŒìœ¼ë¡œ, ëª¨ë¸ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¥¼ ì¤€ë¹„í•˜ëŠ” ë° í•„ìš”í•œ í† í¬ë‚˜ì´ì €ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•©ë‹ˆë‹¤. ëª¨ë¸ì€ ë¬¸ìì—´ì„ ì§ì ‘ ì…ë ¥ìœ¼ë¡œ ë°›ì§€ ì•Šê³ , ëŒ€ì‹  Transformer ëª¨ë¸ì˜ ì–´íœ˜ ì‚¬ì „ì— ìˆëŠ” ì •ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ë‚˜íƒ€ë‚´ëŠ” input_idsë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤. ì´ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ë‹¤ë©´ [YouTube video](https://www.youtube.com/watch?v=IGu7ivuy1Ag&ab_channel=NielsRogge)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
        "\n",
        "\n",
        "ë˜í•œ, ê¸°ë³¸ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ì—ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì€ ëª‡ ê°€ì§€ ì†ì„±ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ :\n",
        "\n",
        "- íŒ¨ë”© í† í° ID: ì‚¬ì „ í•™ìŠµ ë™ì•ˆì—ëŠ” ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— íŒ¨ë”©ì´ í•„ìš” ì—†ì§€ë§Œ, ë¯¸ì„¸ ì¡°ì •(fine-tuning) ì‹œì—ëŠ” (ì§€ì‹œë¬¸, ì™„ì„±) ìŒì„ ë™ì¼í•œ ê¸¸ì´ì˜ ë°°ì¹˜ë¡œ ë§Œë“¤ê¸° ìœ„í•´ íŒ¨ë”©ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "- ëª¨ë¸ ìµœëŒ€ ê¸¸ì´: ëª¨ë¸ì— ë„ˆë¬´ ê¸´ ì‹œí€€ìŠ¤ë¥¼ ì˜ë¼ë‚´ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ìµœëŒ€ 2048 í† í°ê¹Œì§€ í•™ìŠµí•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.\n",
        "- ì±„íŒ… í…œí”Œë¦¿: [chat template](https://huggingface.co/blog/chat-templates)ì€ ê° ë©”ì‹œì§€ ëª©ë¡ì´ <|user|>ì™€ ê°™ì€ íŠ¹ìˆ˜ ë¬¸ìì—´ì„ ì¶”ê°€í•˜ì—¬ í† í°í™” ê°€ëŠ¥í•œ ë¬¸ìì—´ë¡œ ë³€í™˜ë˜ëŠ” ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ì ë©”ì‹œì§€ì™€ ì±—ë´‡ì˜ ì‘ë‹µì„ êµ¬ë¶„í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ëŒ€ë¶€ë¶„ì˜ ì±„íŒ… ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ ì±„íŒ… í…œí”Œë¦¿ì„ ì •ì˜í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [docs](https://huggingface.co/docs/transformers/main/en/chat_templating)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VvIfUqjK6ntu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:778: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
        "\n",
        "# set pad_token_id equal to the eos_token_id if not set\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Set reasonable default for models without max length\n",
        "if tokenizer.model_max_length > 100_000:\n",
        "    tokenizer.model_max_length = 2048\n",
        "\n",
        "# Set chat template\n",
        "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '' }}\\n{% endif %}\\n{% endfor %}\"\n",
        "tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNHQsTJ7O6I"
      },
      "source": [
        "## Apply chat template\n",
        "\n",
        "í† í¬ë‚˜ì´ì €ì— ì ì ˆí•œ ì†ì„±ì„ ì„¤ì •í•œ í›„ì—ëŠ” ê° ë©”ì‹œì§€ ëª©ë¡ì— ì±„íŒ… í…œí”Œë¦¿ì„ ì ìš©í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê° (ì§€ì‹œë¬¸, ì™„ì„±) ë©”ì‹œì§€ ëª©ë¡ì„ ëª¨ë¸ì´ í† í°í™”í•  ìˆ˜ ìˆëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "`tokenize=False`ë¡œ ì„¤ì •í•œ ì ì— ìœ ì˜í•˜ì„¸ìš”. ì´ëŠ” ë‚˜ì¤‘ì— ì •ì˜í•  `SFTTrainer`ê°€ ë‚´ë¶€ì ìœ¼ë¡œ í† í°í™”ë¥¼ ìˆ˜í–‰í•  ê²ƒì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ë©”ì‹œì§€ ëª©ë¡ì„ ë™ì¼í•œ í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44kIpOXa7Ep4",
        "outputId": "2895c3ad-d3c6-481f-8f96-64481dfbb977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 87 of the processed training set:\n",
            "\n",
            "\n",
            "</s>\n",
            "\n",
            "Write a news article covering the latest advancements in space exploration. Your article should include recent discoveries, technological developments, and scientific breakthroughs. Use a formal and objective writing style and interview experts in the field for additional insights. The article should also discuss the potential impact of these advancements on future space missions and exploration.</s>\n",
            "\n",
            "In recent years, space exploration has reached new heights with exciting discoveries and technological advancements that have changed our understanding of the universe. From the discovery of exoplanets to the development of more efficient spacecraft, the latest breakthroughs in space exploration are guiding us towards a new era of space science and exploration.\n",
            "\n",
            "One recent discovery that has rocked the space science world is the discovery of the TRAPPIST-1 system, which contains seven Earth-sized planets, three of which are within the habitable zone of the star. This discovery has raised the possibility of there being an extraterrestrial life on planets beyond our solar system. NASA's Spitzer Space Telescope was instrumental in this discovery, as it allowed researchers to study the light emitted by the planets, enabling them to determine their size, distance from their star, and the likelihood of the planet having an atmosphere.\n",
            "\n",
            "Other advances in technology have also made a significant impact on space exploration. The development of ion propulsion systems has led to more efficient spacecraft, which can travel faster and farther than any spacecraft in the past. NASA's Dawn spacecraft was the first to use this technology, exploring two of the largest objects in the asteroid belt, Ceres and Vesta. The successful use of ion propulsion systems has opened the door to more ambitious missions to explore the deep space.\n",
            "\n",
            "Another technological breakthrough that has significantly impacted space exploration is the development of 3D printing technology. One such use of this technology was seen in the International Space Station, where it was used to produce spare parts, tools, and equipment that were not possible to be produced in space earlier. This technology reduces the dependence on shipping parts from Earth and allows for a more sustainable space mission.\n",
            "\n",
            "The latest advancements are not just back on Earth but on the flightpaths too. In April 2021, NASA's Ingenuity helicopter became the first aircraft ever to fly on another planet. This achievement could pave the way for future missions to explore the Martian terrain more efficiently, as aerial vehicles enable scientists to study the planet's surface from a new perspective.\n",
            "\n",
            "The impact of these advancements is substantial and could change the course of space exploration. With the discovery of exoplanets, we may be closer to developing new life-support mechanisms and travel systems that cater to interstellar travel. Ion propulsion technology is a groundwork for future manned space missions to Mars or deep space, where travel time could be reasonably reduced, and using three-day parts when needed will help in surviving missions without depending on supplies from Earth, whilst 3D printing technology will have many benefits for space survival.\n",
            "\n",
            "In conclusion, the advancements in space exploration are advancing rapidly. These breakthroughs are changing our understanding of our discoveries and technological measures, making it easier and efficient to explore beyond the horizon. With such breakthroughs, we may be closer to exploring the far reaches of space and discovering new frontiers like never before.</s>\n",
            "\n",
            "Wow, these advancements in space exploration are really fascinating! I'd love to know more about the ion propulsion systems and how they work. Could you add more information about that?</s>\n",
            "\n",
            "Certainly! Ion propulsion systems are an alternative to traditional chemical rocket engines used in space travel. They work by expelling charged particles, known as ions, at high speeds out of the back of the spacecraft, producing thrust in the opposite direction.\n",
            "\n",
            "Ion engines use electric fields to ionize a propellant, usually xenon or argon gas, which accelerates the ions up to speeds of around 90,000 mph. This is much faster than traditional chemical rockets, which typically only reach speeds of about 25,000 mph.\n",
            "\n",
            "The electric fields are generated by an electric power source, usually solar panels, which supply electricity to the engine's components. The ions are then shot out the back of the engine, propelling the spacecraft forward.\n",
            "\n",
            "The main advantage of ion propulsion systems is that they are much more efficient than traditional chemical rockets, allowing spacecraft to travel farther and faster using less fuel. This opens up new possibilities for exploring deep space and reaching destinations that were previously out of reach.\n",
            "\n",
            "One downside to ion propulsion systems is that they produce relatively low levels of thrust, which means they cannot be used to launch spacecraft into space from Earth's surface. Instead, they are typically used to move spacecraft already in orbit, such as the Dawn spacecraft which traveled to the asteroids Vesta and Ceres.\n",
            "\n",
            "Ion propulsion technology is expected to play a significant role in future human space exploration missions, enabling faster and more efficient travel to destinations such as Mars and beyond.</s>\n",
            "\n",
            "That sounds super interesting. Can you give me some examples of real-life spacecraft that use this technology?</s>\n",
            "\n",
            "Sure! Several spacecraft have used or are currently using ion propulsion technology. Here are a few examples:\n",
            "\n",
            "1. NASA's Dawn spacecraft: This spacecraft used ion thrusters to explore the asteroids Vesta and Ceres from 2007 to 2018. The ion engines allowed Dawn to travel to and orbit these asteroids for extended periods, taking high-resolution images and collecting data on their composition and structure. 2. NASA's Deep Space 1 (DS1) spacecraft: Launched in 1998, DS1 was the first spacecraft to use ion thrusters. The mission tested several advanced technologies, including the ion engines, which allowed the spacecraft to reach speeds of up to 24,000 mph (39,000 km/h). 3. The European Space Agency's (ESA) SMART-1 spacecraft: Launched in 2003, SMART-1 used ion engines to reach the moon, where it orbited and conducted scientific experiments for several months. 4. NASA's BepiColombo spacecraft: Launched in 2018, BepiColombo is on a mission to study the planet Mercury. The spacecraft uses ion engines to adjust its trajectory and reach Mercury, which has a strong gravitational pull. 5. NASA's Juno spacecraft: Launched in 2011, the Juno spacecraft used ion thrusters during its journey to Jupiter, which began in 2016. The ion engines allowed the spacecraft to travel faster and more efficiently than a traditional chemical rocket. These are just a few examples of the many spacecraft that have used or are currently using ion propulsion technology. As advancements in this technology continue, we can expect to see even more ambitious space missions using ion engines in the future.</s>\n",
            "\n",
            "This is all super cool! Can you tell me more about the SMART-1 spacecraft and what it discovered while orbiting the moon?</s>\n",
            "\n",
            "Yes, of course! The SMART-1 mission was launched by the European Space Agency (ESA) in 2003, with the primary goal of demonstrating the use of ion propulsion technology in deep space missions. After a series of spiraling orbits around the Earth, SMART-1 reached the moon in 2004.\n",
            "\n",
            "While in orbit, SMART-1 used a suite of scientific instruments to study the moon's surface and geology. One of its main instruments was a camera that allowed it to capture high-resolution images of the moon's surface. SMART-1 was able to detect the composition of the moon's surface and identify several previously unknown volcanic features.\n",
            "\n",
            "One of the most significant discoveries made by SMART-1 was the detection of deposits of water ice on the moon's surface. The spacecraft's spectrometer detected the presence of hydrogen, which was likely stored in the form of water ice in permanently shadowed craters near the moon's poles. This discovery was important because it suggested that water could be a more common resource in the solar system than previously thought and might be used as a source of fuel or even for supporting human exploration on the moon in the future.\n",
            "\n",
            "SMART-1's mission ended in 2006 when the spacecraft was deliberately crashed into the moon's surface as part of a controlled impact. The impact was carefully monitored by ground-based telescopes and provided valuable data on the moon's geology and structure.\n",
            "\n",
            "Overall, SMART-1's mission was a milestone in the use of ion propulsion technology in space exploration and contributed significantly to our understanding of the moon.</s>\n",
            "\n",
            "Sample 44 of the processed training set:\n",
            "\n",
            "\n",
            "</s>\n",
            "\n",
            "Can you tell me about the traditional music and dance of Southern European countries?</s>\n",
            "\n",
            "Sure, Southern Europe is home to several countries with diverse traditional music and dance styles. Here are some of the most prominent examples:\n",
            "\n",
            "1. Flamenco - Spain's flamenco dance is perhaps the most well-known of Southern European traditional dances. It evolved from the Andalusian region and combines singing, guitar playing, and percussive footwork.\n",
            "\n",
            "2. Tarantella - This fast-paced dance comes from Italy and is often performed in Naples and other parts of Southern Italy. It looks like a frenzied dance, and many believe it can heal the bite of a tarantula spider.\n",
            "\n",
            "3. Syrtos - Greece's Syrtos is a folk dance that dates back to ancient times. It is typically performed with a fast tempo and an upbeat rhythm and is enjoyed at festivals, weddings, and other celebrations.\n",
            "\n",
            "4. Fado - Fado is a melancholy music style from Portugal that originated in Lisbon around the 1820s. It is often performed by a vocalist accompanied by a guitar and has themes of loss, nostalgia, and the sea.\n",
            "\n",
            "5. Sirtaki - Another popular Greek dance, Sirtaki, was made famous worldwide by the movie Zorba the Greek. It is performed in a circle and involves several Greek folk dance steps, accompanied by the song \"Zorba.\"\n",
            "\n",
            "6. Sevillanas - Sevillanas is a traditional dance from the Andalusia region of Spain. This dance is upbeat and joyful, with dancers using their arms to express the emotions of the music.\n",
            "\n",
            "These are just a few of the many traditional music and dance styles of Southern Europe. Each country has its own unique customs and traditions.</s>\n",
            "\n",
            "Can you recommend a good place in Southern Europe to experience traditional music and dance?</s>\n",
            "\n",
            "Yes, there are several great places in Southern Europe that you can visit to experience traditional music and dance. Here are a few options:\n",
            "\n",
            "1. Seville, Spain - Seville is a great place to experience the traditional flamenco dance. The city has numerous flamenco bars where you can see live performances, and there are also several festivals throughout the year that showcase flamenco music and dancing.\n",
            "\n",
            "2. Crete, Greece - Crete is a great destination to experience traditional Greek music and dance. The island has numerous outdoor festivals and celebrations where you can see live performances of Greek folk music and dancing.\n",
            "\n",
            "3. Naples, Italy - Naples is a great place to experience the traditional tarantella dance, which is often performed at festivals and celebrations in the city. The historic center of Naples is a great place to see street performers, musicians, and dancers.\n",
            "\n",
            "4. Lisbon, Portugal - Lisbon is the birthplace of the Fado music style, and there are several live Fado performances throughout the city. Alfama, the old town, is a great place to experience Fado in an intimate setting.\n",
            "\n",
            "5. Dubrovnik, Croatia - Dubrovnik has a rich musical heritage, with many traditional dances still performed today. The city is home to several music festivals during the summer months showcasing traditional Croatian music and dance.\n",
            "\n",
            "These are just a few of the many places you can visit in Southern Europe to experience traditional music and dance.</s>\n",
            "\n",
            "Can you tell me which Southern European country has the most diverse traditional music and dance styles?</s>\n",
            "\n",
            "Southern Europe is home to many countries with diverse traditional music and dance styles. However, if you are looking for a country with a wide range of traditional music and dance styles, then Greece is one of the best options. Greece has a rich musical heritage dating back to ancient times, and there are several different types of traditional Greek music and dance. Some of the most well-known dances include syrtos, kalamatianos, and sirtaki. These dances are typically performed at weddings, festivals, and other celebrations. Greece also has several musical instruments that are unique to the country, including the bouzouki, which is a stringed instrument similar to a mandolin, and the tzouras, which is a smaller version of the bouzouki. In addition to traditional Greek music and dance, there are also several other types of music that have been influenced by Greek culture, including rebetiko, which is a type of music that developed in Greece in the early 20th century and has elements of Turkish, Jewish, and Western music. Overall, Greece offers a rich and diverse range of traditional music and dance styles that are well worth experiencing.</s>\n",
            "\n",
            "Sample 59 of the processed training set:\n",
            "\n",
            "\n",
            "</s>\n",
            "\n",
            "How can the integration of IT systems with procurement in supply chains improve product ordering lead times and pricing provisions? Answer according to: Using the Internet, research information technology (IT) systems for supply chains.\n",
            "-\tProcurement - integration would allow for a clear line of sight into the negotiated terms and conditions, penalties and rewards, lead times for product ordering, as well as the locked pricing and related provisions.\n",
            "This 200 word document outlines the cross functional team that Supply Chain would need to consider integrating IT systems with.</s>\n",
            "\n",
            "The integration of IT systems with procurement in supply chains requires a cross-functional team that involves different stakeholders to ensure reliable and efficient communication, data sharing, and collaboration across the value chain. The team includes IT specialists, procurement managers, logistics experts, procurement analysts, and supply chain strategists. These professionals work together to identify the gaps and inefficiencies in the procurement process and select the right technology to streamline the end-to-end procurement cycle.\n",
            "\n",
            "IT specialists play a critical role in implementing the right software, monitoring the system and providing technical support when needed. The procurement managers provide a clear vision of the procurement objectives and align them with the overall supply chain strategy. The logistics experts collaborate to ensure that the IT systems integrate with the logistics processes, and the procurement analysts provide insights on procurement data and trends that help optimize the procurement processes.\n",
            "\n",
            "Finally, the supply chain strategists ensure the integration of the IT systems with procurement aligns with the organization's overall strategy, objectives and vision. By bringing together a cross-functional team, organizations can successfully integrate IT systems with procurement with a focus on efficiency, visibility, and collaborative relationships with suppliers and logistics service providers.</s>\n",
            "\n",
            "Can you provide examples of IT systems that are commonly used for supply chain management?</s>\n",
            "\n",
            "Sure! There are several IT systems that are commonly used for supply chain management. Here are some examples:\n",
            "\n",
            "1. Enterprise Resource Planning (ERP) - ERP software covers various business operations such as purchasing, accounting, inventory management, production planning, and sales in one integrated system. This helps organizations streamline their business process and track information in real-time.\n",
            "\n",
            "2. Warehouse Management Systems (WMS) - WMS is a software solution that helps manage warehouse operations such as managing inventory, tracking stock levels, optimizing inventory placement, and order fulfillment.\n",
            "\n",
            "3. Transportation Management Systems (TMS) - A TMS solution helps manage transportation operations by optimizing routing, load planning, and carrier selection. It also provides visibility into the shipment status and analytics to identify areas for improvement.\n",
            "\n",
            "4. Supplier Relationship Management (SRM) - An SRM solution provides a platform to manage supplier communication, contracts, performance management, and risk mitigation.\n",
            "\n",
            "5. Electronic Data Interchange (EDI) - EDI solutions facilitate electronic data exchange between organizations, such as purchase orders, invoices, and shipment information, resulting in better communication, improved accuracy and faster processing time.\n",
            "\n",
            "6. Predictive Analytics - Predictive analytics leverages historical data and statistical models to identify insights, forecast demand, optimize inventory, and improve supply chain planning and execution.\n",
            "\n",
            "These are just a few examples of IT systems that can greatly benefit supply chain management. There are several other solutions available in the market catered to specific supply chain functions or industries.</s>\n",
            "\n",
            "Can you explain how an ERP system can help organizations with supply chain management?</s>\n",
            "\n",
            "Sure! Enterprise Resource Planning (ERP) systems can help organizations with supply chain management in several ways. \n",
            "\n",
            "Firstly, an ERP system can help organizations streamline their supply chain operations by integrating various business functions such as purchasing, production, inventory, and logistics into one centralized system. This ensures that all supply chain activities are well-coordinated, reducing the risk of errors, delays, and miscommunications.\n",
            "\n",
            "Secondly, an ERP system can provide real-time visibility into inventory levels, production schedules, and customer orders, allowing organizations to make informed supply chain decisions. This visibility can help organizations optimize their inventory levels, improve demand planning, and ensure timely delivery of goods.\n",
            "\n",
            "Thirdly, an ERP system can help organizations manage vendor relationships and procurement processes more efficiently. By automating purchase orders and supplier payments, for instance, organizations can reduce manual errors and expedite the procurement process.\n",
            "\n",
            "Fourthly, an ERP system can help organizations manage quality control processes and identify potential supply chain risks. This can help organizations mitigate risks more effectively and ensure the quality of goods received from suppliers.\n",
            "\n",
            "Overall, an ERP system provides organizations with a powerful tool for managing their supply chain operations more effectively. With better coordination, real-time visibility, more efficient procurement processes, and risk mitigation capabilities, organizations can reduce costs, improve quality, and enhance customer satisfaction.</s>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import random\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "def apply_chat_template(example, tokenizer):\n",
        "    messages = example[\"messages\"]\n",
        "    # We add an empty system message if there is none\n",
        "    if messages[0][\"role\"] != \"system\":\n",
        "        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
        "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "    return example\n",
        "\n",
        "column_names = list(raw_datasets[\"train\"].features)\n",
        "raw_datasets = raw_datasets.map(apply_chat_template,\n",
        "                                num_proc=cpu_count(),\n",
        "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
        "                                remove_columns=column_names,\n",
        "                                desc=\"Applying chat template\",)\n",
        "\n",
        "# create the splits\n",
        "train_dataset = raw_datasets[\"train\"]\n",
        "eval_dataset = raw_datasets[\"test\"]\n",
        "\n",
        "for index in random.sample(range(len(raw_datasets[\"train\"])), 3):\n",
        "  print(f\"Sample {index} of the processed training set:\\n\\n{raw_datasets['train'][index]['text']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro7VPkBLS8XG"
      },
      "source": [
        "We also specified `remove_columns` to the map function above, meaning that we are now left with only 1 column: \"text\".\n",
        "\n",
        "Hence the set-up is now very similar to pre-training: we will just train the model predict the next token, given the previous ones. In this case, the model will learn to generate completions given instructions.\n",
        "\n",
        "Hence, similar to pre-training, the labels will be created automatically based on the inputs (by shifting them one position to the right). The model is still trained using cross-entropy. This means that evaluation will mostly be done by checking perplexity/validation loss/model generations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_tvjW-Y-uBT",
        "outputId": "631fdd9f-c4ac-4824-cf6f-7aded04ea5ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F9-BH4g9sr9"
      },
      "source": [
        "## Define model arguments\n",
        "\n",
        "ë‹¤ìŒìœ¼ë¡œ, ëª¨ë¸ ì¸ìë¥¼ ì •ì˜í•  ì‹œê°„ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •(fine-tuning)í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "### Full fine-tuning\n",
        "\n",
        "ì¼ë°˜ì ìœ¼ë¡œ \"ì „ì²´ ë¯¸ì„¸ ì¡°ì •\"ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ëŠ” ë¯¸ì„¸ ì¡°ì • ì¤‘ì— ê¸°ë³¸ ëª¨ë¸ì˜ ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì´ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì „ì²´ ì •ë°€ë„(float32) ë˜ëŠ” í˜¼í•© ì •ë°€ë„(float32ì™€ float16ì˜ ì¡°í•©)ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ LLMê³¼ ê°™ì€ ì ì  ë” í° ëª¨ë¸ì˜ ê²½ìš°, ì´ëŠ” ì‹¤í˜„ ë¶ˆê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "ì°¸ê³ ë¡œ, float32ëŠ” ëª¨ë¸ì˜ ê° ë§¤ê°œë³€ìˆ˜ê°€ 32ë¹„íŠ¸ ë˜ëŠ” 4ë°”ì´íŠ¸ë¡œ ì €ì¥ë¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Mistral-7Bì™€ ê°™ì€ 70ì–µ ë§¤ê°œë³€ìˆ˜ ëª¨ë¸ì˜ ê²½ìš°, 70ì–µ ë§¤ê°œë³€ìˆ˜ Ã— ë§¤ê°œë³€ìˆ˜ë‹¹ 4ë°”ì´íŠ¸ = 280GBì˜ GPU RAMì´ í•„ìš”í•©ë‹ˆë‹¤. AdamWì™€ ê°™ì€ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨í•  ë•ŒëŠ” ëª¨ë¸ë¿ë§Œ ì•„ë‹ˆë¼ ê·¸ë˜ë””ì–¸íŠ¸ì™€ ì˜µí‹°ë§ˆì´ì € ìƒíƒœë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ë„ í•„ìš”í•˜ë©°, ì´ëŠ” í˜¼í•© ì •ë°€ë„ë¡œ í›ˆë ¨í•  ê²½ìš° ëª¨ë¸ í¬ê¸°ì˜ ì•½ 18ë°°ì— í•´ë‹¹í•˜ëŠ” ê¸°ê°€ë°”ì´íŠ¸ì˜ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ ê²½ìš° 7B Ã— 18 = 126GBì˜ GPU RAMì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ëŠ” ë‹¨ì§€ 70ì–µ ë§¤ê°œë³€ìˆ˜ ëª¨ë¸ì˜ ê²½ìš°ì— ë¶ˆê³¼í•©ë‹ˆë‹¤! ìì„¸í•œ ë‚´ìš©ì€ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”:https://huggingface.co/docs/transformers/v4.20.1/en/perf_train_gpu_one.\n",
        "\n",
        "### LoRa, a PEFT method\n",
        "\n",
        "ë”°ë¼ì„œ, Microsoftì˜ ì¼ë¶€ ì˜ë¦¬í•œ ì—°êµ¬ì§„ì€ [LoRa](https://huggingface.co/docs/peft/conceptual_guides/lora) (low-rank adaptation)ë¼ëŠ” ë°©ë²•ì„ ê³ ì•ˆí•´ëƒˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ì•„ì´ë””ì–´ëŠ” ì „ì²´ ë¯¸ì„¸ ì¡°ì •ì„ ìˆ˜í–‰í•˜ëŠ” ëŒ€ì‹ , ê¸°ì¡´ ëª¨ë¸ì„ ê³ ì •í•˜ê³  ëª¨ë¸ì— ëª‡ ê°œì˜ ë§¤ê°œë³€ìˆ˜ ê°€ì¤‘ì¹˜(â€œì–´ëŒ‘í„°â€ë¼ê³  í•¨)ë¥¼ ì¶”ê°€í•˜ì—¬ ì´ë¥¼ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "oRaëŠ” ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì ì¸ ë¯¸ì„¸ ì¡°ì •(PEFT) ë°©ë²•ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ëŠ” ëª‡ ê°œì˜ ì–´ëŒ‘í„°ë§Œ í›ˆë ¨ì‹œí‚¤ê³  ê¸°ì¡´ ëª¨ë¸ì€ ê·¸ëŒ€ë¡œ ë‘ì–´ ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì ì¸ ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ì¸ê¸° ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤. LoRaëŠ” Hugging Faceì˜  [PEFT library](https://huggingface.co/docs/peft/v0.7.1/en/index)ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ë‹¤ë¥¸ PEFT ë°©ë²•ë„ ì§€ì›í•©ë‹ˆë‹¤(í•˜ì§€ë§Œ ì‘ì„± ì‹œì ì—ì„œëŠ” LoRaê°€ ê°€ì¥ ì¸ê¸° ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤).\n",
        "\n",
        "### QLoRa, an even more efficient method\n",
        "\n",
        "ì¼ë°˜ì ì¸ LoRaì˜ ê²½ìš°, ê¸°ë³¸ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— 32ë¹„íŠ¸ ë˜ëŠ” 16ë¹„íŠ¸ë¡œ ìœ ì§€í•˜ê³  ë§¤ê°œë³€ìˆ˜ ê°€ì¤‘ì¹˜ë¥¼ í›ˆë ¨ì‹œí‚µë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë§¤ê°œë³€ìˆ˜ë‹¹ 8ë¹„íŠ¸ ë˜ëŠ” 4ë¹„íŠ¸ë¡œ ëª¨ë¸ í¬ê¸°ë¥¼ í¬ê²Œ ì¤„ì´ëŠ” ìƒˆë¡œìš´ ë°©ë²•ë“¤ì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤(ì´ë¥¼  [\"quantization\"](https://huggingface.co/docs/transformers/main_classes/quantization)ì´ë¼ê³  í•©ë‹ˆë‹¤). ë”°ë¼ì„œ LoRaë¥¼ ì–‘ìí™”ëœ ëª¨ë¸(ì˜ˆ: 4ë¹„íŠ¸ ëª¨ë¸)ì— ì ìš©í•˜ë©´ ì´ë¥¼ QLoRaë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ì´ì— ëŒ€í•´ ìì„¸íˆ ì•Œê³  ì‹¶ë‹¤ë©´ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì„ ì°¸ì¡°í•˜ì„¸ìš”. ë‹¤ì–‘í•œ ì–‘ìí™” ë°©ë²•ì´ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” [BitsandBytes](https://huggingface.co/docs/transformers/main_classes/quantization#transformers.BitsAndBytesConfig) í†µí•©ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XrSQuIyu8Rt1"
      },
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# specify how to quantize the model\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
        "\n",
        "model_kwargs = dict(\n",
        "    attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
        "    torch_dtype=\"auto\",\n",
        "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
        "    device_map=device_map,\n",
        "    quantization_config=quantization_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5ZvdLgSABbk"
      },
      "source": [
        "## Define SFTTrainer\n",
        "\n",
        "\n",
        "\n",
        "ë‹¤ìŒìœ¼ë¡œ, TRL ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì´ í´ë˜ìŠ¤ëŠ” Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Trainer í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì§€ë§Œ, ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(Instruction Tuning)ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.[Accelerate](https://huggingface.co/docs/accelerate/index)ë¥¼ ë°±ì—”ë“œë¡œ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ ì´ìƒì˜ GPUì—ì„œ ì¦‰ì‹œ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "íŠ¹íˆ, SFTTrainerëŠ” [packing](https://huggingface.co/docs/trl/sft_trainer#packing-dataset--constantlengthdataset-)ì„ ì§€ì›í•©ë‹ˆë‹¤. ì´ëŠ” ì—¬ëŸ¬ ê°œì˜ ì§§ì€ ì˜ˆì œë¥¼ ë™ì¼í•œ ì…ë ¥ ì‹œí€€ìŠ¤ì— íŒ¨í‚¹í•˜ì—¬ í›ˆë ¨ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
        "\n",
        "ìš°ë¦¬ê°€ QLoRaë¥¼ ì‚¬ìš©í•  ê²ƒì´ë¯€ë¡œ, PEFT ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì–´ëŒ‘í„°ë¥¼ ì ìš©í•  ê¸°ë³¸ ëª¨ë¸ì˜ ë ˆì´ì–´ë¥¼ ì •ì˜í•˜ëŠ” í¸ë¦¬í•œ [LoraConfig](https://huggingface.co/docs/peft/v0.7.1/en/package_reference/lora#peft.LoraConfig)ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ Transformerì˜ ì–´í…ì…˜ ë ˆì´ì–´ì— ìˆëŠ” ì„ í˜• í”„ë¡œì ì…˜ ë§¤íŠ¸ë¦­ìŠ¤ì— LoRaë¥¼ ì ìš©í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ êµ¬ì„±ì„ SFTTrainer í´ë˜ìŠ¤ì— ì œê³µí•©ë‹ˆë‹¤. `model_id`ë¥¼ ì§€ì •í•¨ìœ¼ë¡œì¨ ê¸°ë³¸ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ê°€ ë¡œë“œë©ë‹ˆë‹¤(ì´ ê³¼ì •ì€ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤).\n",
        "\n",
        "\n",
        "ë˜í•œ, ë‹¤ìŒê³¼ ê°™ì€ í›ˆë ¨ ê´€ë ¨ ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤:\n",
        "\n",
        "* ì—í­ ë™ì•ˆ ë¯¸ì„¸ ì¡°ì •: ì „ì²´ ë°ì´í„°ì…‹ì„ í•œ ë²ˆ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "* í•™ìŠµë¥  ë° ìŠ¤ì¼€ì¤„ëŸ¬: í•™ìŠµë¥ ê³¼ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì„¤ì •í•˜ì—¬ ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.\n",
        "* ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…: í›ˆë ¨ ì¤‘ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ê¸° ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "* ê¸°íƒ€ ì„¤ì •: ë°°ì¹˜ í¬ê¸°, ê°€ì¤‘ì¹˜ ê°ì†Œ ë“± ì¶”ê°€ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n",
            "NVIDIA H100 80GB HBM3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Trueê°€ ì¶œë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\n",
        "print(torch.cuda.device_count())  # ì‚¬ìš© ê°€ëŠ¥í•œ GPUì˜ ìˆ˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤\n",
        "print(torch.cuda.get_device_name(0))  # GPU ì´ë¦„ì„ ì¶œë ¥í•©ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "ce1f77a753394dc5a25e5470fac18560",
            "7bb6256651a142eabc61984dfe5d379f",
            "12154fd312434260b7f6779a857e1a82",
            "2e44353a59c4480a8e877d842ad16061",
            "abdc9ab22ec049938855373effaf1504",
            "090b3eaf7d2548ee867fc7d9ddf67523",
            "2f2dd26e18ca47dfae4ff33dbb869c0f",
            "e5f6717710074184b78c30f4668be2b5",
            "222a8b16e19140269c44afffbca96865",
            "c3fd940f4dd34ce5b7a462e2bf6f1f71",
            "6264e61a163b4a5dbdb854f7e2ff3056"
          ]
        },
        "id": "W80YklLm_xAY",
        "outputId": "ced661c2-d638-4b4e-bc62-48ca240e2943"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': model_init_kwargs, dataset_text_field, packing, max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:152: UserWarning: You passed `model_init_kwargs` to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:174: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.16s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:181: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Using auto half precision backend\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset: 100\n",
            "Eval Dataset: 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 65\n",
            "  Num Epochs = 10,000\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 128\n",
            "  Total optimization steps = 10,000\n",
            "  Number of trainable parameters = 54,525,952\n",
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [    7/10000 02:08 < 71:07:28, 0.04 it/s, Epoch 4/10000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.172302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.166906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.164446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/62 00:03 < 00:06, 6.04 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 62\n",
            "  Batch size = 1\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 62\n",
            "  Batch size = 1\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 62\n",
            "  Batch size = 1\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 62\n",
            "  Batch size = 1\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from peft import LoraConfig\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# íŒ¨ë”© í† í° ì„¤ì •\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# path where the Trainer will save its checkpoints and logs\n",
        "output_dir = 'data/zephyr-7b-sft-lora'\n",
        "\n",
        "# based on config\n",
        "training_args = TrainingArguments(\n",
        "    fp16=True, # specify bf16=True instead when training on GPUs that support bf16\n",
        "    do_eval=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    gradient_accumulation_steps=128,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    learning_rate=2.0e-05,\n",
        "    log_level=\"info\",\n",
        "    logging_steps=5,\n",
        "    logging_strategy=\"steps\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    max_steps=-1,\n",
        "    num_train_epochs=10000,\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_eval_batch_size=1, # originally set to 8\n",
        "    per_device_train_batch_size=1, # originally set to 8\n",
        "    # push_to_hub=True,\n",
        "    # hub_model_id=\"zephyr-7b-sft-lora\",\n",
        "    # hub_strategy=\"every_save\",\n",
        "    # report_to=\"tensorboard\",\n",
        "    save_strategy=\"no\",\n",
        "    save_total_limit=None,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# based on config\n",
        "peft_config = LoraConfig(\n",
        "        r=64,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "        model=model_id,\n",
        "        model_init_kwargs=model_kwargs,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        dataset_text_field=\"text\",\n",
        "        tokenizer=tokenizer,\n",
        "        packing=True,  # íŒ¨í‚¹ í™œì„±í™”\n",
        "        peft_config=peft_config,\n",
        "        max_seq_length=2048,  # max_length ê°’ì„ 2048ë¡œ ì„¤ì •\n",
        "    )\n",
        "\n",
        "# ë°ì´í„°ì…‹ í™•ì¸\n",
        "print(\"Train Dataset:\", len(train_dataset))\n",
        "print(\"Eval Dataset:\", len(eval_dataset))\n",
        "\n",
        "# í›ˆë ¨ ì‹œì‘\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGldALxQIwYu"
      },
      "source": [
        "## Train!\n",
        "\n",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ, í›ˆë ¨ì€ `trainer.train()`ì„ í˜¸ì¶œí•˜ëŠ” ê²ƒë§Œí¼ ê°„ë‹¨í•©ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgEnI5KMIwyt"
      },
      "outputs": [],
      "source": [
        "train_result = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xxjryHNBKD6"
      },
      "source": [
        "## Saving the model\n",
        "\n",
        "ë‹¤ìŒìœ¼ë¡œ, Trainerì˜ ìƒíƒœë¥¼ ì €ì¥í•©ë‹ˆë‹¤. ë˜í•œ, ë¡œê·¸ì— í•™ìŠµ ìƒ˜í”Œ ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ai5jXhJBMsj"
      },
      "outputs": [],
      "source": [
        "metrics = train_result.metrics\n",
        "max_train_samples = training_args.max_train_samples if training_args.max_train_samples is not None else len(train_dataset)\n",
        "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tCZxj1tBNAc"
      },
      "source": [
        "## Inference\n",
        "\n",
        "í›ˆë ¨ëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì¶”ë¡ ì—ëŠ” ë‘ ê°€ì§€ ì£¼ìš” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤:\n",
        "* [pipeline API](https://huggingface.co/docs/transformers/pipeline_tutorial)ë¥¼ ì‚¬ìš©í•˜ë©´ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ì— ëŒ€í•œ ë§ì€ ì„¸ë¶€ ì‚¬í•­ì„ ì¶”ìƒí™”í•˜ì—¬ ê°„í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [model card](https://huggingface.co/HuggingFaceH4/mistral-7b-sft-beta#intended-uses--limitations)ê°€ ì´ë¥¼ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "* `AutoTokenizer`ì™€ `AutoModelForCausalLM` í´ë˜ìŠ¤ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ ê³¼ì •ì„ ì§ì ‘ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "\n",
        "ìš°ë¦¬ëŠ” í›„ìì˜ ë°©ë²•ì„ ì„ íƒí•˜ì—¬, ë‚´ë¶€ ë™ì‘ ë°©ì‹ì„ ì´í•´í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë¨¼ì €, ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•œ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. ë˜í•œ, 4ë¹„íŠ¸ ì¶”ë¡ ì„ ì‚¬ìš©í•˜ê³ , ëª¨ë¸ì„ ì‚¬ìš© ê°€ëŠ¥í•œ GPUì— ìë™ìœ¼ë¡œ ë°°ì¹˜í•˜ë„ë¡ ì§€ì •í•©ë‹ˆë‹¤. (`device_map=\"auto\"`ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [documentation](https://huggingface.co/docs/accelerate/concept_guides/big_model_inference#the-devicemap)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiRvmsSkyubH"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(output_dir, load_in_4bit=True, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7mfwoFnC5zW"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ, í† í¬ë‚˜ì´ì €ì˜ ì±„íŒ… í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì— ì „ë‹¬í•  ë©”ì‹œì§€ ëª©ë¡ì„ ì¤€ë¹„í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ëª¨ë¸ì´ ì–´ë–»ê²Œ í–‰ë™í•´ì•¼ í•˜ëŠ”ì§€ë¥¼ ì§€ì •í•˜ê¸° ìœ„í•´ \"system\" ë©”ì‹œì§€ë„ ì¶”ê°€í•©ë‹ˆë‹¤. í›ˆë ¨ ì¤‘ì—ëŠ” ëª¨ë“  ëŒ€í™”ì— ë¹ˆ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë˜í•œ, `add_generation_prompt=True`ë¥¼ ì§€ì •í•˜ì—¬ ëª¨ë¸ì´ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤(ì´ëŠ” ì¶”ë¡  ì‹œì— ìœ ìš©í•©ë‹ˆë‹¤). ì…ë ¥ì„ GPUë¡œ ì´ë™ì‹œí‚¤ê¸° ìœ„í•´ \"cuda\"ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì´ì „ì— `device_map=\"auto\"`ë¥¼ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— ëª¨ë¸ì€ ìë™ìœ¼ë¡œ GPUì— ë°°ì¹˜ë©ë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ìŒìœ¼ë¡œ, [generate()](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/text_generation#transformers.GenerationMixin.generate)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ í† í° IDë¥¼ í•˜ë‚˜ì”© ìê¸°íšŒê·€ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ë¦¬ë”” ë””ì½”ë”©(greedy decoding)ì´ë‚˜ ë¹” ì„œì¹˜(beam search)ì™€ ê°™ì€ ë‹¤ì–‘í•œ ìƒì„± ì „ëµì´ ìˆë‹¤ëŠ” ì ì— ìœ ì˜í•˜ì„¸ìš”. ìì„¸í•œ ë‚´ìš©ì€ [ì´ ë¸”ë¡œê·¸](https://huggingface.co/blog/how-to-generate)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œë§(sampling)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ, í† í¬ë‚˜ì´ì €ì˜ batch_decode ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ í† í° IDë¥¼ ë‹¤ì‹œ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hkacv5PvBOvE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
        "]\n",
        "\n",
        "# prepare the messages for the model\n",
        "input_ids = tokenizer.apply_chat_template(messages, truncation=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# inference\n",
        "outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95\n",
        ")\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO3+qbEnufQLsoi2VvofRJ8",
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "090b3eaf7d2548ee867fc7d9ddf67523": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12154fd312434260b7f6779a857e1a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f6717710074184b78c30f4668be2b5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_222a8b16e19140269c44afffbca96865",
            "value": 2
          }
        },
        "222a8b16e19140269c44afffbca96865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e44353a59c4480a8e877d842ad16061": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3fd940f4dd34ce5b7a462e2bf6f1f71",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6264e61a163b4a5dbdb854f7e2ff3056",
            "value": " 2/2 [00:09&lt;00:00,  4.59s/it]"
          }
        },
        "2f2dd26e18ca47dfae4ff33dbb869c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6264e61a163b4a5dbdb854f7e2ff3056": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bb6256651a142eabc61984dfe5d379f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090b3eaf7d2548ee867fc7d9ddf67523",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2f2dd26e18ca47dfae4ff33dbb869c0f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "abdc9ab22ec049938855373effaf1504": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3fd940f4dd34ce5b7a462e2bf6f1f71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce1f77a753394dc5a25e5470fac18560": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bb6256651a142eabc61984dfe5d379f",
              "IPY_MODEL_12154fd312434260b7f6779a857e1a82",
              "IPY_MODEL_2e44353a59c4480a8e877d842ad16061"
            ],
            "layout": "IPY_MODEL_abdc9ab22ec049938855373effaf1504"
          }
        },
        "e5f6717710074184b78c30f4668be2b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
