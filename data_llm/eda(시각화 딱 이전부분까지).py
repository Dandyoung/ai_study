'''
ì‹¤í–‰ë°©ë²• : streamlit run eda.py 
'''

import streamlit as st
import time
import re
import pandas as pd
import numpy as np
import plotly.figure_factory as ff
import seaborn as sns
import matplotlib.pyplot as plt
from langchain.agents import initialize_agent, AgentType
from langchain.callbacks import StreamlitCallbackHandler
from langchain.chat_models import ChatOpenAI
from langchain.agents import AgentExecutor
from MyAI import MyAI
from MyEDAHelper import MyEDAHelper
import sys
import os

# ëª¨ë“ˆ ê²€ìƒ‰ ê²½ë¡œì— /workspace/youngwoo/Agent_m2m/Pages ì¶”ê°€
sys.path.append(os.path.abspath("/workspace/youngwoo/Agent_m2m/Pages"))
# default_dataframeì—ì„œ create_info_df í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
from default_dataframe import create_info_df

from query_dataframe import QueryDataFrame
db_path = '/workspace/youngwoo/Agent_m2m/Pages/dataset/most_recent.db'
query_tool = QueryDataFrame(db_path, openai_api_key)


def fnc_graph(user_eda_column):    
    with st.container():
        st.scatter_chart(df, y=[user_eda_column])
        st.info('ì‚°ì ë„', icon="âœ¨")
    with st.container():
        st.plotly_chart(figure_or_data=ff.create_distplot([df[user_eda_column].dropna()], group_labels=[user_eda_column]))
        st.info('íˆìŠ¤í† ê·¸ë¨', icon="âœ¨")
    return

'''
ì—¬ê¸°ë¶€í„° ëª¨ë“ˆí™” í•´ì•¼í•¨ í…ŒìŠ¤íŠ¸ìš©
'''
from ml_collections import ConfigDict
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SQLDatabase
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import pandas as pd
from langchain_core.runnables import RunnableLambda
from loguru import logger
import subprocess
import re
from ml_collections import ConfigDict
from langchain_openai import ChatOpenAI
import json

def get_input_gpt(user_message):
    return user_message

def get_template(template,var="custom"):
    if var == "gpt":
        return get_input_gpt(template)

TemplateConfig = ConfigDict()

TemplateConfig.visualization_prompt  = '''
ë‹¹ì‹ ì€ pythonì„ ì´ìš©í•œ ë°ì´í„° ì‹œê°í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ë°ì´í„°ëŠ” '{query}'ì— ë”°ë¼ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ ê²°ê³¼ì…ë‹ˆë‹¤.
ì¶”ì¶œí•œ ë°ì´í„°:
{context}

ë¨¼ì €, ì£¼ì–´ì§„ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ê°€ì¥ ì˜ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ì‹œê°í™” ë°©ë²•ì„ ì•„ë˜ì—ì„œ í•œ ê°€ì§€ ì„ íƒí•˜ì„¸ìš”.

- ì‹œê°í™” ë°©ë²•
TABLE : ë²”ì£¼í˜• ë°ì´í„°, í…ìŠ¤íŠ¸ ë°ì´í„°, ìš”ì•½ í†µê³„ ex) íŠ¹ì • ì‹œê°„ëŒ€ì˜ ë°ì´í„° ìƒíƒœ, ë°ì´í„° ê°’
HEATMAP, BUBBLE, BAR : ë¹ˆë„í˜• ë°ì´í„°, ì—°ì†í˜• ë°ì´í„° ê°„ì˜ ê´€ê³„ ex) ì˜¨ë„, ì••ë ¥, ì¶œë ¥ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶„ì„, íŠ¹ì • ì´ë²¤íŠ¸ ë°œìƒ ë¹ˆë„
SCATTER, TIMELINE, HISTOGRAM : ì—°ì†í˜• ë°ì´í„°, ì‹œê°„ ë°ì´í„° ex) ë°œì „ì†Œì˜ ì¼ë³„ ì¶œë ¥ëŸ‰ ë¶„í¬

ì„ íƒí•œ ì‹œê°í™” ë°©ë²•ì„ ê¸°ë°˜ìœ¼ë¡œ plotlyë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆì„ì„ ì‹œê°í™”í•˜ëŠ” ìˆ˜ì¤€ ë†’ì€ python codeë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë¬´ì¡°ê±´ python codeë§Œ ìƒì„±í•˜ì„¸ìš”.

ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ë°˜ì˜í•˜ì„¸ìš” :

1. ì‹œê°í™”ì˜ ìœ í˜•ì— ê´€ê³„ì—†ì´ ì»¬ëŸ¼ ë„“ì´ì™€ í–‰ ë†’ì´ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
2. ì‹œê°í™”ì— ì œëª©ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
3. ì‹œê°í™”ì˜ ì»¬ëŸ¬ í…Œë§ˆë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
4. ì‹œê°í™”ì˜ ìš”ì†Œ ì •ë ¬ ë° í°íŠ¸ ì„¤ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.
5. ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ì„ ì ì ˆíˆ ë‚˜ëˆ„ì–´ ì—¬ëŸ¬ ê°œì˜ ì‹œê°í™”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
6. dfëŠ” ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
7. ìƒì„±ëœ ì‹œê°í™” ì´ë¯¸ì§€ëŠ” './tmp_img' í´ë”ì— ì €ì¥ë˜ê²Œ í•´ì£¼ì„¸ìš”.

ì¶œë ¥ ì–‘ì‹ :
```python\n<python code>\n```
'''

llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')
TEMPLATE_MODEL = 'gpt'

def make_visualization_prompt(state)->ChatPromptTemplate:
    prompt = TemplateConfig.visualization_prompt.format_map({"query":state["query"],
                                                                "context":state["context"]})
    prompt = get_template(prompt,TEMPLATE_MODEL)
    return prompt


# with st.sidebar:
#     st.title("ğŸ’€ Hi, I am :blue[Agent_m2m] ",)

#     openai_api_key = st.text_input(
#         "OpenAI API Key", key="langchain_search_api_key_openai", type="password"
#     )
#     if openai_api_key:
#         myai:MyAI = MyAI(api_key=openai_api_key)
#         if myai:
#             try:
#                 myai.ValidateLLM()    
#                 st.write('You are using LLM: '+ myai.GetLLM().model_name)                
#             except Exception as e:
#                 #st.write(e)
#                 st.error('Please enter a valid  OpenAI API key to continue.', icon="ğŸš¨")
#         else:
#             #st.write('Please add valid  OpenAI API key to continue.')=
#             st.error('Please enter a valid  OpenAI API key to continue.', icon="ğŸš¨")
        

#     "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"
#     "[View the source code](https://github.com/cdebdeep/Agent_m2m.git)"
#     "[Open in GitHub Codespaces](https://ideal-guacamole-q47g9p6xrj24xgj.github.dev/)"

# st.title("ğŸ” EDA - With your file")


# streamlit ì•± ì‹œì‘
st.markdown(
    "<h1 style='text-align: center; font-size: 35px;'>ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” <span style='color: #A61717;'>ìŠ¤ë§ˆíŠ¸ ì— íˆ¬ì— </span> ì…ë‹ˆë‹¤</h1>", 
    unsafe_allow_html=True
)
# OpenAI API í‚¤ê°€ ë¯¸ë¦¬ ì„ ì–¸ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë°”ë¡œ ì§„í–‰
myai = MyAI(api_key=openai_api_key)

st.markdown(
    "<h1 style='text-align: center; font-size: 28px;'>ğŸ” Let's start with <span style='color: #D9D2D0;'>EDA (Exploratory Data Analysis)!</span></h1>", 
    unsafe_allow_html=True
)


# ì—…ë¡œë“œëœ íŒŒì¼ ëŒ€ì‹  ë‚´ë¶€ ë°ì´í„°í”„ë ˆì„ ì‚¬ìš©
st.info('ìˆ˜ì§‘ëœ ê°€ìŠ¤í„°ë¹ˆ ì„¼ì„œ ë°ì´í„°ì…ë‹ˆë‹¤.', icon="ğŸ’â€â™€ï¸")
info_df = create_info_df()                           
# ë°ì´í„°í”„ë ˆì„ì˜ ê° ì—´ íƒ€ì…ì„ í™•ì¸í•˜ê³  ë³€í™˜
for col in info_df.columns:
    if info_df[col].dtype == 'object':
        try:
            info_df[col] = pd.to_numeric(info_df[col])
        except ValueError:
            info_df[col] = info_df[col].astype(str)

st.write(info_df.shape)
st.dataframe(info_df)


tab1, tab2, tab3, tab4 = st.tabs(["Q & A", "EDA","EDA-ê·¸ë˜í”„", "ìƒì„±"])

with tab1:
    st.header("ğŸ“Š Q & A  ")
    question1 = st.text_input(
        "ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”",
        placeholder="ì˜ˆ: 24ì¼ ê°€ìŠ¤ê´€ë ¨ ë°ì´í„°ì˜ í‰ê· ê°’ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ?",
        disabled=False,
    )
    if question1:
        try:
            with st.spinner("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”, ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... !"):
                # ì—¬ê¸°ì„œ ë°›ëŠ” dfê°€ ì¿¼ë¦¬ ì‹¤í–‰ëœ ë°ì´í„°
                df = query_tool.query_dataframe(question1, info_df)
                agentexecutor = myai.GetAgentExecutor(df=df)
                myedahelper = MyEDAHelper(agentexecutor)
                retval = myedahelper.fnc_qa(question1,info_df, df)

                logger.debug("ì²´ì¸ ì‹¤í–‰ ì¤‘..")
                Chain__split_query = (RunnableLambda(make_visualization_prompt)| llm | StrOutputParser())
                tmp = Chain__split_query.invoke({"query": question1,"context": df}).strip()
                start_idx = tmp.find("```python") + len("```python")
                end_idx = tmp.find("```", start_idx)
                tmp_python_code = tmp[start_idx:end_idx].strip()

                print(tmp_python_code)
                # Execute the Python code
                # local_vars = {}
                # exec(tmp_python_code, {"df": df}, local_vars)

                temp_dir = "/workspace/youngwoo/Agent_m2m/Pages/tmp"
                temp_script_path = os.path.join(temp_dir, "temp_script.py")

                with open(temp_script_path, "w") as f:
                    f.write(tmp_python_code)

                # print(f"retval :{retval}")
                st.success(retval, icon="âœ…")
        except Exception as e:
            st.error('í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ !!.', icon="ğŸš¨")    

# with tab2:
#     st.header("EDA")
#     question2 = st.text_input(
#         "EDAë¥¼ ìœ„í•´ ë°ì´í„° ì—´ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”",
#         placeholder="ì—´ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”?",
#         disabled=False,
#     )
#     if question2:
#         try:
#             with st.spinner("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”, ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... !"):                  
#                 st.success('ë‹¤ìŒì€ ì‘ë‹µì…ë‹ˆë‹¤:', icon="âœ…")
#                 myedahelper = MyEDAHelper(agentexecutor)
#                 retval = myedahelper.fnc_eda(question2)
#                 message_placeholder = st.empty()                

#                 # Simulate stream of response with milliseconds delay
#                 full_response = ""
#                 for chunk in re.split(r'(\s+)', retval):
#                     full_response += chunk + " "
#                     time.sleep(0.01)

#                     # Add a blinking cursor to simulate typing
#                     message_placeholder.markdown(full_response + "â–Œ")

#         except Exception as e:
#             st.error('í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ !!.', icon="ğŸš¨")

# with tab3:
#     st.header("EDA-ê·¸ë˜í”„")
#     question3 = st.text_input(
#         "EDA ê·¸ë˜í”„ë¥¼ ìœ„í•´ ë°ì´í„° ì—´ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”",
#         placeholder="ì—´ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”?",
#         disabled=False,
#     )
#     if question3:
#         try:
#             with st.spinner("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”, ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... !"):
#                 fnc_graph(question3)
#         except Exception as e:
#             st.error('í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ !!.', icon="ğŸš¨")            

# with tab4:
#     st.header("ìƒì„±")
#     question4 = st.text_input(
#         "ì—¬ê¸°ì— ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
#         placeholder="ì˜ˆ: 'ì—´ ì´ë¦„ì´ 10ë³´ë‹¤ ì‘ì€ ê²½ìš°?",
#         disabled=False,
#     )
#     if question4:
#         try:
#             with st.spinner("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”, ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... !"):
#                 myedahelper = MyEDAHelper(agentexecutor)
#                 retval = myedahelper.fnc_modifydata(question4)
#                 if not retval.empty:
#                     st.success('ì „ì²´ í–‰ê³¼ ì—´ì˜ ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:', icon="âœ…")
#                     st.write(retval.shape)
#                     st.write(retval)
#         except Exception as e:
#             st.error(e, icon="ğŸš¨")

# st.write("ë°©ë¬¸í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!")

